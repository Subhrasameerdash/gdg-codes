{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17cb6f9-c759-4609-851b-4f8ddf5dcae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      student_answer  \\\n",
      "0  1.  Discuss how the concept of biodiversity ne...   \n",
      "1  1.  A scientist discovers a new chemical that ...   \n",
      "2  1.  **Comparative Analysis:** C3 and C4 plants...   \n",
      "3  1.  A scientist is studying two plant cells: C...   \n",
      "4  1.  A scientist is studying a plant species th...   \n",
      "\n",
      "                                        model_answer  score  grade  \\\n",
      "0  ### Summary ###\\nThe living world is rich in v...     92    A**   \n",
      "1  ### Summary ###\\nAccording to the cell theory,...     95    A**   \n",
      "2  ### Summary ###\\ncould be drawn?\\n11.2 EARLY E...     88  ** B+   \n",
      "3  ### Summary ###\\nequation for this\\n\\n### Defi...     95   ** A   \n",
      "4  ### Summary ###\\nGrowth is one of the most con...     88    A**   \n",
      "\n",
      "                                            feedback  \n",
      "0  **\\n\\nThis is an exceptionally well-written an...  \n",
      "1  **\\n\\n**Strengths:**\\n\\n*   Excellent understa...  \n",
      "2  No feedback provided.\\nOkay, let's evaluate th...  \n",
      "3  **\\n\\n*   **Strengths:** The student demonstra...  \n",
      "4  **\\n\\n**Strengths:**\\n\\n*   **Accuracy (32/35)...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Folder path containing structured JSON files\n",
    "TRAINING_DATA_FOLDER = \"training_data\"\n",
    "\n",
    "# Load JSON samples into a DataFrame\n",
    "data = []\n",
    "\n",
    "# Iterate over JSON files and load them\n",
    "for file_name in os.listdir(TRAINING_DATA_FOLDER):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(TRAINING_DATA_FOLDER, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            sample = json.load(f)\n",
    "            data.append({\n",
    "                \"student_answer\": sample[\"input\"][\"student_answer\"],\n",
    "                \"model_answer\": sample[\"input\"][\"model_answer\"],\n",
    "                \"score\": sample[\"output\"][\"score\"],\n",
    "                \"grade\": sample[\"output\"][\"grade\"],\n",
    "                \"feedback\": sample[\"output\"][\"feedback\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display dataset sample\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c636643-9e99-4adb-9d8c-cd7b3f7e8506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Feedback:\n",
      " ## Overall Assessment\n",
      "\n",
      "Your answers demonstrate a good understanding of the concepts covered in the model answer. You've addressed the questions thoroughly and provided clear explanations. The use of examples and justifications strengthens your responses.\n",
      "\n",
      "**Score:** 85/100\n",
      "**Grade:** A\n",
      "\n",
      "## Detailed Feedback\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "*   **Comprehensive Understanding:** You display a solid grasp of biodiversity, nomenclature, the biological species concept, and dichotomous keys.\n",
      "*   **Clear Explanations:** Your explanations are articulated well and easy to follow. You break down complex concepts into simpler terms.\n",
      "*   **Relevant Examples:** You effectively use the example of *Mangifera indica* and create your own hypothetical insect species to illustrate the concepts.\n",
      "*   **Justification:** You provide strong justifications for your choices, such as the characteristics used in the dichotomous key.\n",
      "*   **Addresses Limitations:** You acknowledge the limitations of Mayr's definition and the dichotomous key, demonstrating a critical understanding of the subject matter.\n",
      "*   **Well-Organized Answers:** Each answer is logically structured and presented in a clear and coherent manner.\n",
      "\n",
      "**Areas for Improvement:**\n",
      "\n",
      "*   **Depth of Explanation (Biological Species Definition):** While you explain Mayr's definition well, you could delve deeper into the nuances and complexities surrounding reproductive isolation. Consider mentioning different mechanisms of reproductive isolation (prezygotic and postzygotic).\n",
      "*   **Expanding on Dichotomous Key Justification:** While your justification for the dichotomous key characteristics is good, you could briefly mention some alternative characteristics that might *not* be as suitable and *why* (e.g., behavioral traits, which can be more difficult to observe and standardize).\n",
      "*   **Model Answer Incorporation:** Explicitly referencing/incorporating the vocabulary of the Model Answer and including the title headings would help improve the grade.\n",
      "\n",
      "**Specific Suggestions:**\n",
      "\n",
      "*   **Question 2 (Mayr's Definition):** Expand on the different types of reproductive isolation (e.g., habitat isolation, temporal isolation, behavioral isolation, mechanical isolation, gametic isolation, hybrid inviability, hybrid sterility, hybrid breakdown).\n",
      "*   **Question 3 (Dichotomous Key):** Briefly discuss why certain characteristics (e.g. size) might be less reliable for a dichotomous key than the features you have chosen.\n",
      "\n",
      "By incorporating these suggestions, you can further enhance the depth and sophistication of your answers. Keep up the good work!\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import time\n",
    "\n",
    "# Set up Gemini API key\n",
    "GOOGLE_API_KEY = \"AIzaSyDxtvmaGC9iB53VkvyYbtcBZKgOVg9Z2S8\"  \n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Function to generate feedback\n",
    "def generate_feedback_gemini(student_answer, model_answer, retries=3, delay=5):\n",
    "    \"\"\"\n",
    "    Uses Google Gemini to generate feedback by comparing student and model answers.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI teacher grading a CBSE class 11-12 student's answer.\n",
    "    Compare the student's answer with the model answer and provide:\n",
    "    - A score between 0-100\n",
    "    - A grade (A, B, C, D, F)\n",
    "    - Detailed feedback on strengths and areas for improvement.\n",
    "\n",
    "    **Model Answer:**\n",
    "    {model_answer}\n",
    "\n",
    "    **Student Answer:**\n",
    "    {student_answer}\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            time.sleep(delay)\n",
    "            model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "            response = model.generate_content(prompt)\n",
    "\n",
    "            if response.candidates and response.candidates[0].content.parts:\n",
    "                return response.candidates[0].content.parts[0].text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Attempt {attempt + 1} failed: {e}\")\n",
    "\n",
    "    return \"Feedback generation failed.\"\n",
    "\n",
    "\n",
    "# Example Usage: Generate feedback for the first sample\n",
    "feedback = generate_feedback_gemini(df['student_answer'][0], df['model_answer'][0])\n",
    "print(\"Generated Feedback:\\n\", feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43bf4dd-6190-40a5-9eea-4b650a265982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully:\n",
      "                                      student_answer  \\\n",
      "0  1.  Discuss how the concept of biodiversity ne...   \n",
      "1  1.  A scientist discovers a new chemical that ...   \n",
      "2  1.  **Comparative Analysis:** C3 and C4 plants...   \n",
      "3  1.  A scientist is studying two plant cells: C...   \n",
      "4  1.  A scientist is studying a plant species th...   \n",
      "\n",
      "                                        model_answer  score  grade  \\\n",
      "0  ### Summary ###\\nThe living world is rich in v...     92    A**   \n",
      "1  ### Summary ###\\nAccording to the cell theory,...     95    A**   \n",
      "2  ### Summary ###\\ncould be drawn?\\n11.2 EARLY E...     88  ** B+   \n",
      "3  ### Summary ###\\nequation for this\\n\\n### Defi...     95   ** A   \n",
      "4  ### Summary ###\\nGrowth is one of the most con...     88    A**   \n",
      "\n",
      "                                            feedback  \n",
      "0  **\\n\\nThis is an exceptionally well-written an...  \n",
      "1  **\\n\\n**Strengths:**\\n\\n*   Excellent understa...  \n",
      "2  No feedback provided.\\nOkay, let's evaluate th...  \n",
      "3  **\\n\\n*   **Strengths:** The student demonstra...  \n",
      "4  **\\n\\n**Strengths:**\\n\\n*   **Accuracy (32/35)...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Loss: 4.4491\n",
      "Epoch 2/3\n",
      "Loss: 4.0156\n",
      "Epoch 3/3\n",
      "Loss: 3.6650\n",
      "✅ Model training complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# === Disable Hugging Face Symlink Warning ===\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "# === Step 1: Load the Dataset ===\n",
    "TRAINING_DATA_FOLDER = \"training_data\"\n",
    "\n",
    "# Load JSON samples into a DataFrame\n",
    "data = []\n",
    "\n",
    "# Iterate over JSON files and load them\n",
    "for file_name in os.listdir(TRAINING_DATA_FOLDER):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(TRAINING_DATA_FOLDER, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            sample = json.load(f)\n",
    "            data.append({\n",
    "                \"student_answer\": sample[\"input\"][\"student_answer\"],\n",
    "                \"model_answer\": sample[\"input\"][\"model_answer\"],\n",
    "                \"score\": sample[\"output\"][\"score\"],\n",
    "                \"grade\": sample[\"output\"][\"grade\"],\n",
    "                \"feedback\": sample[\"output\"][\"feedback\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"✅ Dataset loaded successfully:\")\n",
    "print(df.head())\n",
    "\n",
    "# === Step 2: Define the Dataset Class ===\n",
    "class GradingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for BERT fine-tuning.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        student_answer = str(self.df.loc[index, \"student_answer\"])\n",
    "        model_answer = str(self.df.loc[index, \"model_answer\"])\n",
    "        label = self.df.loc[index, \"score\"]  # Score as label\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            student_answer + \" [SEP] \" + model_answer,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# === Step 3: Model Training ===\n",
    "def train_model(df, batch_size=8, epochs=3, learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Fine-tunes BERT for grading.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Tokenizer and dataset\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    dataset = GradingDataset(df, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Load pre-trained BERT\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=101)\n",
    "    model.to(device)\n",
    "\n",
    "    # Use PyTorch's AdamW to avoid deprecation warning\n",
    "    from torch.optim import AdamW\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(\"edu_feedback_bert_model\")\n",
    "    tokenizer.save_pretrained(\"edu_feedback_bert_model\")\n",
    "\n",
    "    print(\"✅ Model training complete!\")\n",
    "\n",
    "# === Train the model ===\n",
    "train_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a961f12-8082-495a-b743-9cf2670a19aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
